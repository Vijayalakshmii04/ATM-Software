{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyORX5XC2wn+LhPlN/ZnNfgr",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Vijayalakshmii04/ATM-Software/blob/main/adct_project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch numpy\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3NPiVdkzbM40",
        "outputId": "d6f81fee-f11a-4032-9ddc-8abeebb9c5ad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (2.8.0+cu126)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (2.0.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch) (3.20.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch) (3.4.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch) (3.0.3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "import heapq\n",
        "from collections import Counter\n"
      ],
      "metadata": {
        "id": "cemeL0slbRUo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TextTokenizer:\n",
        "    def __init__(self):\n",
        "        self.special = {'<PAD>':0, '<UNK>':1, '<START>':2, '<END>':3}\n",
        "        self.char_to_idx = dict(self.special)\n",
        "        self.idx_to_char = {v:k for k,v in self.char_to_idx.items()}\n",
        "\n",
        "    def fit(self, text):\n",
        "        chars = sorted(set(text))\n",
        "        offset = len(self.special)\n",
        "        for i,c in enumerate(chars):\n",
        "            self.char_to_idx[c] = i + offset\n",
        "\n",
        "        self.idx_to_char = {v:k for k,v in self.char_to_idx.items()}\n",
        "\n",
        "    def encode(self, text, add_special=True):\n",
        "        ids = [self.char_to_idx.get(c,1) for c in text]\n",
        "        if add_special:\n",
        "            return [2] + ids + [3]\n",
        "        return ids\n",
        "\n",
        "    def decode(self, ids):\n",
        "        return ''.join(self.idx_to_char.get(i,\"\") for i in ids)\n"
      ],
      "metadata": {
        "id": "b3Ig5ztobV7V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class LSTMPredictor(nn.Module):\n",
        "    def __init__(self, vocab_size, embed_dim=64, hidden_dim=128):\n",
        "        super().__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, embed_dim)\n",
        "        self.lstm = nn.LSTM(embed_dim, hidden_dim,\n",
        "                            batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_dim, vocab_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.embedding(x)\n",
        "        out,_ = self.lstm(x)\n",
        "        logits = self.fc(out)\n",
        "        probs = F.softmax(logits, dim=-1)\n",
        "        return probs\n"
      ],
      "metadata": {
        "id": "qx-TQSTCbaSy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model(model, data, epochs=20):\n",
        "    opt = torch.optim.Adam(model.parameters(), lr=0.01)\n",
        "    loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "    for ep in range(epochs):\n",
        "        x = torch.tensor([data[:-1]], dtype=torch.long)\n",
        "        y = torch.tensor([data[1:]], dtype=torch.long)\n",
        "\n",
        "        opt.zero_grad()\n",
        "        probs = model(x)\n",
        "        loss = loss_fn(probs.reshape(-1, probs.size(-1)),\n",
        "                       y.reshape(-1))\n",
        "        loss.backward()\n",
        "        opt.step()\n",
        "\n",
        "        if ep % 5 == 0:\n",
        "            print(\"Epoch\", ep, \"Loss:\", loss.item())\n"
      ],
      "metadata": {
        "id": "9TLnI_sHbfZ7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def arithmetic_encode(text_ids, prob_seq):\n",
        "    low, high = 0.0, 1.0\n",
        "\n",
        "    for i, true_id in enumerate(text_ids):\n",
        "        probs = prob_seq[i]  # list of probabilities\n",
        "        cum = 0.0\n",
        "\n",
        "        for idx, pr in enumerate(probs):\n",
        "            if idx == true_id:\n",
        "                new_low  = low + (high - low) * cum\n",
        "                new_high = low + (high - low) * (cum + pr)\n",
        "                low, high = new_low, new_high\n",
        "                break\n",
        "            cum += pr\n",
        "\n",
        "    return (low + high) / 2\n"
      ],
      "metadata": {
        "id": "pU8VffoWbjMF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Node:\n",
        "    def __init__(self, char=None, freq=None, left=None, right=None):\n",
        "        self.char = char\n",
        "        self.freq = freq\n",
        "        self.left = left\n",
        "        self.right = right\n",
        "\n",
        "    def __lt__(self, other):\n",
        "        return self.freq < other.freq\n",
        "\n",
        "def build_huffman(text):\n",
        "    freqs = Counter(text)\n",
        "    heap = [Node(c,f) for c,f in freqs.items()]\n",
        "    heapq.heapify(heap)\n",
        "\n",
        "    while len(heap)>1:\n",
        "        a = heapq.heappop(heap)\n",
        "        b = heapq.heappop(heap)\n",
        "        merged = Node(None, a.freq + b.freq, a, b)\n",
        "        heapq.heappush(heap, merged)\n",
        "\n",
        "    return heap[0]\n",
        "\n",
        "def generate_codes(node, prefix=\"\", codes={}):\n",
        "    if node.char:\n",
        "        codes[node.char]=prefix or \"0\"\n",
        "    else:\n",
        "        generate_codes(node.left, prefix+\"0\", codes)\n",
        "        generate_codes(node.right, prefix+\"1\", codes)\n",
        "    return codes\n"
      ],
      "metadata": {
        "id": "STCT-GBlbmu6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def compress_text(input_text):\n",
        "    tokenizer = TextTokenizer()\n",
        "    tokenizer.fit(input_text)\n",
        "    encoded = tokenizer.encode(input_text)\n",
        "\n",
        "    print(\"Input Text:\", input_text)\n",
        "    print(\"Token IDs:\", encoded)\n",
        "\n",
        "    # ---- Train LSTM ----\n",
        "    model = LSTMPredictor(len(tokenizer.char_to_idx))\n",
        "    train_model(model, encoded, epochs=15)\n",
        "\n",
        "    # ---- Get LSTM probabilities ----\n",
        "    x = torch.tensor([encoded[:-1]], dtype=torch.long)\n",
        "    probs = model(x).detach().numpy()[0]   # shape = (len-1, vocab_size)\n",
        "\n",
        "    prob_seq = []  # list of probability LISTS\n",
        "\n",
        "    print(\"\\n===== LSTM TOP-3 PROBABILITIES =====\")\n",
        "    for i, p in enumerate(probs):\n",
        "\n",
        "        # save correct probability format (list)\n",
        "        prob_seq.append(list(p))\n",
        "\n",
        "        # print readable top-3\n",
        "        char_probs = [(tokenizer.idx_to_char[idx], float(p[idx]))\n",
        "                      for idx in range(len(p))]\n",
        "        top3 = sorted(char_probs, key=lambda x: x[1], reverse=True)[:3]\n",
        "\n",
        "        print(f\"\\nAt position {i} after '{tokenizer.idx_to_char[encoded[i]]}':\")\n",
        "        for char, pr in top3:\n",
        "            print(f\"   {char}: {pr:.4f}\")\n",
        "\n",
        "    # ---- Arithmetic Encoding ----\n",
        "    print(\"\\n===== ARITHMETIC ENCODED TAG =====\")\n",
        "    tag = arithmetic_encode(encoded[1:], prob_seq)   # correct input format\n",
        "    print(\"Tag:\", tag)\n",
        "\n",
        "    # ---- Huffman Codes ----\n",
        "    print(\"\\n===== HUFFMAN CODES =====\")\n",
        "    huff_tree = build_huffman(input_text)\n",
        "    huff_codes = generate_codes(huff_tree)\n",
        "    print(huff_codes)\n",
        "\n",
        "    return tag, huff_codes\n",
        "\n"
      ],
      "metadata": {
        "id": "VxmeYS8Jbq2x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sample_text = \"Vellore Institute of Technology\"\n",
        "tag, huffman = compress_text(sample_text)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NQ7XzzE3bz5p",
        "outputId": "780608ff-38fe-4856-82cb-f6b99647ec82"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input Text: Vellore Institute of Technology\n",
            "Token IDs: [2, 7, 9, 14, 14, 16, 17, 9, 4, 5, 15, 18, 19, 13, 19, 20, 19, 9, 4, 16, 10, 4, 6, 9, 8, 12, 15, 16, 14, 16, 11, 21, 3]\n",
            "Epoch 0 Loss: 3.090259552001953\n",
            "Epoch 5 Loss: 2.739793062210083\n",
            "Epoch 10 Loss: 2.3846354484558105\n",
            "\n",
            "===== LSTM TOP-3 PROBABILITIES =====\n",
            "\n",
            "At position 0 after '<START>':\n",
            "   V: 0.6098\n",
            "   e: 0.2554\n",
            "   l: 0.0249\n",
            "\n",
            "At position 1 after 'V':\n",
            "   e: 0.9966\n",
            "   l: 0.0014\n",
            "   V: 0.0013\n",
            "\n",
            "At position 2 after 'e':\n",
            "   l: 0.9939\n",
            "   c: 0.0029\n",
            "   e: 0.0011\n",
            "\n",
            "At position 3 after 'l':\n",
            "   l: 0.9664\n",
            "   o: 0.0311\n",
            "   e: 0.0015\n",
            "\n",
            "At position 4 after 'l':\n",
            "   o: 0.9904\n",
            "   l: 0.0055\n",
            "   r: 0.0031\n",
            "\n",
            "At position 5 after 'o':\n",
            "   r: 0.9744\n",
            "   g: 0.0190\n",
            "   e: 0.0019\n",
            "\n",
            "At position 6 after 'r':\n",
            "   e: 0.9945\n",
            "    : 0.0024\n",
            "   r: 0.0022\n",
            "\n",
            "At position 7 after 'e':\n",
            "    : 0.9891\n",
            "   I: 0.0039\n",
            "   e: 0.0029\n",
            "\n",
            "At position 8 after ' ':\n",
            "   I: 0.9890\n",
            "   n: 0.0025\n",
            "   o: 0.0020\n",
            "\n",
            "At position 9 after 'I':\n",
            "   n: 0.9803\n",
            "   I: 0.0082\n",
            "   s: 0.0068\n",
            "\n",
            "At position 10 after 'n':\n",
            "   s: 0.9954\n",
            "   o: 0.0012\n",
            "   n: 0.0010\n",
            "\n",
            "At position 11 after 's':\n",
            "   t: 0.9833\n",
            "   s: 0.0098\n",
            "   u: 0.0025\n",
            "\n",
            "At position 12 after 't':\n",
            "   u: 0.9077\n",
            "   t: 0.0634\n",
            "   e: 0.0207\n",
            "\n",
            "At position 13 after 'i':\n",
            "   t: 0.9845\n",
            "   u: 0.0136\n",
            "    : 0.0009\n",
            "\n",
            "At position 14 after 't':\n",
            "   u: 0.9839\n",
            "   e: 0.0084\n",
            "   t: 0.0053\n",
            "\n",
            "At position 15 after 'u':\n",
            "   t: 0.9870\n",
            "   u: 0.0053\n",
            "    : 0.0028\n",
            "\n",
            "At position 16 after 't':\n",
            "   e: 0.9782\n",
            "   u: 0.0188\n",
            "    : 0.0021\n",
            "\n",
            "At position 17 after 'e':\n",
            "    : 0.9944\n",
            "   e: 0.0013\n",
            "   c: 0.0013\n",
            "\n",
            "At position 18 after ' ':\n",
            "   o: 0.9395\n",
            "   t: 0.0158\n",
            "   T: 0.0117\n",
            "\n",
            "At position 19 after 'o':\n",
            "   o: 0.2272\n",
            "    : 0.1697\n",
            "   r: 0.1660\n",
            "\n",
            "At position 20 after 'f':\n",
            "    : 0.9810\n",
            "   T: 0.0066\n",
            "   e: 0.0064\n",
            "\n",
            "At position 21 after ' ':\n",
            "   T: 0.9651\n",
            "   I: 0.0249\n",
            "   o: 0.0030\n",
            "\n",
            "At position 22 after 'T':\n",
            "   e: 0.9959\n",
            "   c: 0.0013\n",
            "   T: 0.0008\n",
            "\n",
            "At position 23 after 'e':\n",
            "   c: 0.9941\n",
            "   h: 0.0023\n",
            "   l: 0.0009\n",
            "\n",
            "At position 24 after 'c':\n",
            "   h: 0.9681\n",
            "   c: 0.0254\n",
            "   e: 0.0021\n",
            "\n",
            "At position 25 after 'h':\n",
            "   n: 0.9960\n",
            "   h: 0.0012\n",
            "   o: 0.0006\n",
            "\n",
            "At position 26 after 'n':\n",
            "   o: 0.9925\n",
            "   s: 0.0034\n",
            "   l: 0.0023\n",
            "\n",
            "At position 27 after 'o':\n",
            "   l: 0.9903\n",
            "   g: 0.0044\n",
            "   o: 0.0033\n",
            "\n",
            "At position 28 after 'l':\n",
            "   o: 0.9945\n",
            "   l: 0.0028\n",
            "   g: 0.0020\n",
            "\n",
            "At position 29 after 'o':\n",
            "   g: 0.9774\n",
            "   r: 0.0166\n",
            "   y: 0.0030\n",
            "\n",
            "At position 30 after 'g':\n",
            "   y: 0.9935\n",
            "   g: 0.0035\n",
            "   <END>: 0.0020\n",
            "\n",
            "At position 31 after 'y':\n",
            "   <END>: 0.9973\n",
            "   y: 0.0018\n",
            "   g: 0.0004\n",
            "\n",
            "===== ARITHMETIC ENCODED TAG =====\n",
            "Tag: 0.09830984\n",
            "\n",
            "===== HUFFMAN CODES =====\n",
            "{'s': '11010', 'e': '100', 'm': '01000', 'u': '10111', 'p': '010100', 'd': '010101', 'i': '01011', 'C': '011000', 'U': '0110010', 'G': '0110011', 'f': '10110', 'P': '0110110', 'v': '0110111', 'h': '01010', 'y': '11101', 'g': '11011', 'â€™': '0111100', ',': '0111101', '.': '011111', 'c': '01000', 'w': '10010', 'n': '1010', 'b': '100111', ' ': '001', 't': '000', 'o': '011', 'r': '11100', 'l': '1111', 'a': '11111', 'I': '01001', 'T': '11000', 'V': '11001'}\n"
          ]
        }
      ]
    }
  ]
}